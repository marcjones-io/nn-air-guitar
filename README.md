# The Best Air Guitar Yet

#### yes air guitars are passé
#### yes modeling software instruments after real-life ones is a cliché
#### ... and, yes this project had to be done because _no one has done it like we have._

This group project arose out of Universitat Pompeu Fabra's Advanced Interface Design course competition and ultimately took the top prize for best design and implementation.

### Team:
- Guillem Arias Bedmar (Cambridge / UPF)
- Marc Jones (UVA / UPF)
- Jake Phillips (Perdue / UPF)

We embedded a glove with resistive flex sensors (one for each finger) to communicate with a neural network, and thus trained the nn on various finger positions with MIDI data to output prescribed chords via [open sound control (OSC)](https://en.wikipedia.org/wiki/Open_Sound_Control). Further, guitar strums are generated by mobile device accelerometer variations (generated by flicking ones wrist), and accomplished using an accompanying custom OSC template installed to an Android or iOS device. The two OSC output sources (glove-nn and mobile device) are then recieved by a Max patch for sound generation and note-vizualization over time (similar to a piano roll style format).

### Tech that made this possible:
- [TensorFlow by Google](https://www.tensorflow.org)
- [Max MSP by Cycling '74](https://cycling74.com/products/max/)
- [TouchOSC by Hexler](https://hexler.net/software/touchosc)
- [SpicyGuitar by Pierre-André and Benoît](http://www.spicyguitar.com)
- [Flex Sensors from SparkFun](https://www.sparkfun.com/products/8606)

### _presentation video coming soon!_
